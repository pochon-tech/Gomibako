**準備**
- `docker-compose exec node sh`

**AWKについて**

- フィルタプログラムを構成できる
- AWK が得意とする入力データは，表（テーブル，table）形式のテキストデータ
- 表データの各行（横方向）のデータ集合をレコード、各列（縦方向）のデータ集合をフィールド（field）と呼ぶ
|  Name  |  Age  |
| ---- | ---- |
|  Mike  |  20  |
|  Juin  |  40  |
- 表データをテキストファイルで表現する場合、各フィールドの間を「タブ」もしくは「空白」で区切る
- レコード単位の処理: パターン（正規表現や条件式）にマッチしたレコードに対してだけ， アクション（処理）を実行
  - `パターン { アクション }`: パターンに一致した行だけに対してアクションを実行
  - `アクション`: デフォルトのパターン。全ての行に対してアクションを実行

**構文**
- `$ awk '{ awkのコード }' ファイル名`

**練習**
- ファイル内容出力
```sh:
$ vi sample.dat
1 10 100
2 20 200
3 30 300
# 変数「$0」には、現在処理している一行の内容が格納
$ awk '{ print $0; }' sample.dat
```

- 各行の、各列を出力
```sh:
# $0: 現在処理している1行
# $1,$2...: 処理している1行を「空白で分割」して格納される
# "hoge": ""で括られた文字は文字列として表示
$ awk '{ print $1","$2","$3; }' sample.dat
1,10,100
2,20,200
3,30,300
```

- 計算結果の出力
```sh:
$ awk '{ print "+: "$1+$2+$3; print "-: "$3-$2-$1; print "*: "$1*$2*$3; print "/: "$3/$2/$1 }' sample.dat 
+: 111
-: 89
*: 1000
/: 10
+: 222
-: 178
*: 8000
/: 5
+: 333
-: 267
*: 27000
/: 3.33333
# 小数点の桁数を指定して出力
$ awk '{ printf "%.6f\n", $1 }' sample.dat
1.000000
2.000000
3.000000
# 余り計算
$ awk '{ print $2%3 }' sample.dat 
1 # 10 % 3 = 3...1
2 # 20 % 3 = 6...2
0 # 30 % 3 = 10...0
# 変数に格納
$ awk '{ sum = $1+$2+$3; print sum} ' sample.dat
111
222
333
```

- 正規表現を使う
- `awk '/正規表現/ { アクション }'`
```sh:
# 2を含む行を表示
$ awk '/2/ { print $0 }' sample.dat
2 20 200
# 100で終わる行を表示
$ awk '/100$/ { print $0 }' sample.dat
1 10 100
```

- BEGINとEND
- `awk 'BEGIN { 最初の行を読み込む前の処理 } { メイン処理 } END { 最後の行を読み込んだ後の処理 }'`
```sh:
# BEGIN: 最初の行が読み込まれる前に処理を実行
# END:   最後の行が読み込まれた後に処理を実行
# 一番最初の行と、一番最後の行に文字を表示する。
awk 'BEGIN { print "==BEGIN==" } { print $0} END { print "==END==" }' sample.dat 
==BEGIN==
1 10 100
2 20 200
3 30 300
==END==
```

- awkスクリプトファイルを読み込む
```sh:
vi sample.awk
#!/usr/bin/awk -f
{
    # all record output
    print $0;
}
$ awk -f sample.awk sample.dat
1 10 100
2 20 200
3 30 300
# chmod +x sample.awk のように実行権限を付与してあげれば、ファイルからの実行も可能
$ ./sample.awk sample.dat
1 10 100
2 20 200
3 30 300
# 複数ファイルも指定可能
$ cp sample.dat sample2.dat
$ ./sample.awk sample.dat sample2.dat
```

### sed,awk,grepの活用

- sed: 文字列を置換
- awk: 文字列を抽出
- grep: 文字列を検索

**文字列の置換**

- `sed -e "s/置換元/置換後/g" ファイル名`
  - -e: 指定したスクリプト（条件式）で変換処理を行う
  - s:  置換元を置換後に変換する」を表す
  - g:  「条件を満たす"すべての"文字列を置換する」を表す
  - 置換元: 正規表現で記述可
  - 置換後: \1や\2で、置換元でマッチした文字を取ってこれる
```sh:
$ vi sum.php
<?php
function sum ($a, $b)
{
    return $a+$b;
}
$ cat sum.php
$ cp sum.php sum2.php
# xargs: 標準入力やファイルからリストを読み込み、コマンドラインを作成して実行する
# . xargs [オプション] コマンド [コマンドの引数]
# . 「コマンドA | xargs コマンドB」で、コマンドAの実行結果を引数にしてコマンドBを実行
# sedで、複数の置換を連続して行う場合は、複数のパターンを同時に書く a->targetAの次にb->targetB
# findで置換対象のファイルを探索して、一度で複数ファイルに対して実行する
# find -print0 | xargs -0 を使う理由は下記
# . lsコマンドの結果からわかるように、スペースが含まれるファイル名は、別々なものとして認識される。
# . xargsは区切り文字として空白文字(改行、スペース、タブなど)を使っているため、下のサンプルが示すように、空白と改行の両方を区切り文字として扱ってしまう
# . echo -e "Hello World\nHelloWorld" | xargs -n1 echo
# . 処理の前後関係としては、xargsが空白文字でなくヌル文字を区切りとして扱うように-0を指定し、xargsの形式に合わせるためにfindの-print0を指定する
# sed -iの後ろに指定の文字列を追加すると、元のファイル名 + iオプションに指定した文字列 として残っている
# 下記のコマンドは、findで拡張子PHPのファイルを探索して、見つかったファイルそれぞれに対して、置換するという処理
$ find . -type f -name "*.php" -print0 | xargs -0 sed -i.bak -e "s/\$a/\$targetA/g" -e "s/\$b/\$targetB/g"
```
